
## 1. 신용카드 사기 거래 탐지 AI 경진대회 월간 데이콘
###  (1위) 매우 간단한 1D AutoEncoder 활용한 신용카드 사기 거래 탐지 AI(Macro f1 score : 0.926)
[https://www.dacon.io/competitions/official/235930/codeshare/5508?page=1&dtype=recent](https://www.dacon.io/competitions/official/235930/codeshare/5508?page=1&dtype=recent)

1. **데이터 수집 및 전처리**
	- 데이터셋 : 정상, 사기 거래의 여부를 알 수 없는 신용 카드 데이터 (Unlabeled)
		* ID : 신용 카드 거래 ID
		* Column ('V1', 'V2', 'V3', ... ,'V30) : 비식별화된 신용 카드 거래 Feature
	- 데이터 전처리: 이상치 제거, 정규화 등 기본적인 전처리 수행

2. **사용된 모듈 및 라이브러리**
	- PyTorch : 딥러닝 프레임워크
		- 주요 기능: 동적 계산 그래프, GPU 가속, 다양한 신경망 모델 구현에 용이
		- 가이드: [PyTorch Tutorials](https://tutorials.pytorch.kr)
	- sklearn : 데이터 분석 패키지
		- 주요 기능: 데이터 전처리, 지도학습, 비지도학습 모델 제공
		- 가이드: [Scikit-learn User Guide](https://scikit-learn.org/stable/user_guide.html)
	- numpy : 수치 계산 패키지
		- 주요 기능: 다차원 배열 객체 제공, 수학적 함수 라이브러리
		- 가이드: [Numpy Documentation](https://numpy.org/doc/stable/user/quickstart.html)
	- pandas : 데이터 조작 및 분석 라이브러리
		- 주요 기능: 데이터프레임 자료구조, 데이터 정리 및 조작 기능 제공
		- 가이드: [Pandas Documentation](https://pandas.pydata.org/docs/)
	- tqdm
		: 프로그래스 바 라이브러리
		- 주요 기능: 루프 진행 상황을 시각적으로 표시
		- 가이드: TQDM Documentation
		76%|████████████████████████        | 7568/10000 [00:33<00:10, 229.00it/s]
		
3.  **모델 구성**
	- AutoEncoder : 비지도 학습 기반의 데이터 차원 축소 및 노이즈 제거 모델
		*  입력 데이터를 낮은 차원으로 압축변환한 후, 다시 원래의 데이터로 복원하는 방식으로 작동
		*  데이터의 차원 축소, 특징 추출, 잡음 제거 등에 사용
		- 구성: 인코더, 디코더
		- PyTorch를 이용한 모델 구현: `torch.nn.Module`을 상속받아 인코더와 디코더 네트워크를 정의


	1. **인코더(Encoder)**:
	    - 입력 데이터를 저차원 공간으로 압축합니다.
	    - 입력 데이터 $x$를 받아서 잠재 공간(latent space) 표현 $z$로 변환합니다.
	    - 일반적으로 여러 층의 신경망으로 구성되어 있으며, 차원을 줄이는 역할을 합니다.
	    - 인코더의 출력은 잠재 변수(latent variables) 또는 코드(code)라고 불립니다.
	2. **디코더(Decoder)**:
	    - 인코더에 의해 압축된 데이터를 다시 원래 차원으로 복원합니다.
	    - 잠재 공간 표현 $z$를 받아서 원래 입력 데이터와 유사한 출력 $\hat{x}$로 변환합니다.
	    - 인코더의 반대 역할을 하며, 입력 데이터를 복원하는 역할을 합니다.
		 ![](https://i.imgur.com/fJ6NbSE.png)

``
```python
import torch
import torch.nn as nn

class AutoEncoder(nn.Module): 
    def __init__(self): 
        super(AutoEncoder, self).__init__()
        
        # 인코더 (Encoder) 부분
        self.Encoder = nn.Sequential(
            nn.Linear(30, 64),         # 입력 차원 30을 64 차원으로 변환
            nn.BatchNorm1d(64),        # 배치 정규화 (훈련을 안정화하고 가속화)
            nn.LeakyReLU(),            # 활성화 함수로 LeakyReLU 사용
            nn.Linear(64, 128),        # 64 차원을 128 차원으로 변환
            nn.BatchNorm1d(128),       # 배치 정규화
            nn.LeakyReLU()             # 활성화 함수로 LeakyReLU 사용
        ) 
        # 디코더 (Decoder) 부분
        self.Decoder = nn.Sequential(
            nn.Linear(128, 64),        # 128 차원을 64 차원으로 변환
            nn.BatchNorm1d(64),        # 배치 정규화
            nn.LeakyReLU(),            # 활성화 함수로 LeakyReLU 사용
            nn.Linear(64, 30)          # 64 차원을 원래 입력 차원인 30으로 복원
        )
    def forward(self, x):
        # 인코더를 통해 입력 데이터를 잠재 공간으로 변환
        encoded = self.Encoder(x)
        # 디코더를 통해 잠재 공간 데이터를 원래 차원으로 복원
        decoded = self.Decoder(encoded)
        return decoded

# 사용 예시
# 모델 초기화
model = AutoEncoder()
# 임의의 입력 데이터 생성 (batch_size, input_dim) 형태
x = torch.randn(16, 30)  # batch size 16, input dimension 30
# 모델에 입력 데이터를 통과시켜 출력 얻기
output = model(x)
print(output.shape)  # torch.Size([16, 30])

```

4. **모델 학습 및 평가**
	- 학습 과정
		- 학습 데이터 및 검증 데이터 분할 방법: 훈련 데이터와 테스트 데이터로 분할
		- 학습 파라미터 설정: 학습률(LR), 배치 크기(BS), 에폭 수(EPOCHS) 등
		- 옵티마이저: Adam optimizer 사용
	- 평가 지표
		- 사용된 평가 지표: F1-score
		- 평가 결과 및 해석: 모델의 재현율과 정밀도를 고려한 F1-score로 성능 평가





<br>

## 2. 신용카드 사용자 연체 예측 AI 경진대회

### (1위) 팀 소회의실 Catboost(LogLoss 0.6581)
[https://www.dacon.io/competitions/official/235713/codeshare/2768?page=1&dtype=recent](https://www.dacon.io/competitions/official/235713/codeshare/2768?page=1&dtype=recent)

1. **데이터 수집 및 전처리**
    - 데이터셋 : 신용카드 사용자들의 개인 신상정보
    - 데이터 전처리: 이상치 제거, 변수 생성 및 조작 등
2. **사용된 모듈 및 라이브러리**
    - Catboost : 그라디언트 부스팅 라이브러리
        - 주요 기능: 카테고리형 변수 처리를 자동화하여 모델 성능 향상
        - 가이드: Catboost Documentation
    - category_encoders : 범주형 데이터 인코딩 라이브러리
        - 주요 기능: 다양한 범주형 변수 인코딩 방식 제공
        - 가이드: Category Encoders Documentation
    - sklearn : 데이터 분석 패키지
        - 주요 기능: 데이터 전처리, 지도학습, 비지도학습 모델 제공
        - 가이드: [Scikit-learn User Guide](https://scikit-learn.org/stable/user_guide.html)
    - numpy : 수치 계산 패키지
        - 주요 기능: 다차원 배열 객체 제공, 수학적 함수 라이브러리
        - 가이드: Numpy Documentation
    - pandas : 데이터 조작 및 분석 라이브러리
        - 주요 기능: 데이터프레임 자료구조, 데이터 정리 및 조작 기능 제공
        - 가이드: Pandas Documentation
3. **모델 구성**
    - Catboost 모델 : 고성능 그라디언트 부스팅 모델
        - 특징: 카테고리형 변수를 자동으로 처리하여 성능 향상
        - 활용: 특정 대회에서 높은 성능을 기록한 모델
4. **모델 학습 및 평가**
    - 학습 과정
        - 학습 데이터 및 검증 데이터 분할 방법: 훈련 데이터와 테스트 데이터로 분할
        - 학습 파라미터 설정: 하이퍼파라미터 튜닝, 그리드 서치 등
    - 평가 지표
        - 사용된 평가 지표: 정확도, 정밀도, 재현율, F1-score 등
        - 평가 결과 및 해석: 모델의 다양한 성능 지표로 평가


<br>

## 3. 2023 NH 투자증권 빅데이터 경진대회, “블룸버그, 나스닥과 함께 세계속으로!”

### (7위)Fin2Vec : Transformer 기반 종목 간 상관관계 분석 모델
[https://www.dacon.io/competitions/official/236145/codeshare/8902?page=1&dtype=random](https://www.dacon.io/competitions/official/236145/codeshare/8902?page=1&dtype=random)

1. **프로젝트 개요**
    - 프로젝트 목표: 나스닥 및 코스피 기업들 간의 관계성 기반으로 차트 재현 및 관계성 파악 모델 개발
    - 활동 요약:
        - 데이터 크롤링
        - 데이터 전처리 (Pandas, Numpy)   
        - Parallized Convolution Recurrent Network(PCRN) 모델 설계 및 구현
        - PCRN과 Transformer 융합하여 Fin2Vec 모델 설계 및 구현
        - Meta사의 Data2Vec 2.0 모델 차용 및 재설계
        - Fin2Vec를 통한 종목 클러스터링
        - Fin2Vec 활용 방안 제시
2. **데이터 수집 및 전처리**
    - 데이터셋: 2013년부터 2023년 상반기까지의 나스닥 및 코스피 종목 시세 데이터
    - 전처리: 데이터 크롤링, 정규화 및 토크나이징      
3. **사용된 모듈 및 라이브러리**
    - Transformer : 자연어 처리 모델
        - 주요 기능: self-attention 메커니즘을 통한 문맥 이해 및 관계성 학습
        - 활용: 종목 간 관계 분석을 위해 사용
    - PCRN (Parallized Convolution Recurrent Network) : 시계열 데이터 토크나이저
        - 주요 기능: 시계열 데이터를 압축하여 토큰화        
    - Meta Data2Vec 2.0 : 비지도 학습 모델
        - 주요 기능: 종목 간 관계성 학습에 활용    
    - Pandas : 데이터 조작 및 분석 라이브러리
        - 주요 기능: 데이터프레임 자료구조, 데이터 정리 및 조작 기능 제공    
        - 가이드: Pandas Documentation    
    - Numpy : 수치 계산 패키지
        - 주요 기능: 다차원 배열 객체 제공, 수학적 함수 라이브러리
        - 가이드: Numpy Documentation
4. **모델 구성**
    - Fin2Vec 모델 : Transformer와 PCRN을 융합한 모델
        - 구성: PCRN 인코더로 시계열 데이터 토크나이징, Transformer로 종목 간 관계성 학습
        - 활용: 종목 간 관계성 분석, 예측 및 군집화 작업
5. **모델 학습 및 평가**
    - 학습 과정:
        - 데이터 준비: 종목별 시세 데이터 수집 및 전처리
        - 모델 훈련: PCRN을 통한 토크나이징, Transformer로 관계성 학습
        - 하이퍼파라미터 설정: 학습률(LR), 배치 크기(BS), 에폭 수(EPOCHS) 등
    - 평가 지표:
        - 모델 성능 평가: 정확도, 정밀도, 재현율, F1-score 등

   
